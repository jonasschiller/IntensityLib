{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper.flowtracing as ft\n",
    "import helper.entsoe_wrapper as entsoe_wrapper\n",
    "from entsoe import EntsoePandasClient\n",
    "import helper.capacity as cap\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Tracing\n",
    "\n",
    "- 27 European Countries with Generation, Load, Import and Export\n",
    "- Entsoe Client is used to load the data for the Generation and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates in UTC\n",
    "start_utc = pd.Timestamp('2022-01-01', tz='UTC')\n",
    "end_utc = pd.Timestamp('2023-01-01', tz='UTC')\n",
    "\n",
    "# Codes for the Countries in the List\n",
    "countryCodes=[\"AT\",\"PT\",\"ES\",\"FR\",\"IT\",\"GR\",\"ME\",\"BG\",\"RO\",\"RS\",\"HU\",\"SK\",\"SI\",\"CZ\",\"BE\",\"NL\",\"EE\",\"LV\",\"LT\",\"FI\",\"NO\",\"SE\",\"DK\",\"PL\",\"DE\",\"IE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"96ebcf8b-a543-4309-b167-322d5e0d5684\"\n",
    "client=EntsoePandasClient(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_wrapper.get_import_data(\"PT\",start_utc,end_utc).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT\n",
      "PT\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#   Load data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gen_dict,gen_types\u001b[38;5;241m=\u001b[39mentsoe\u001b[38;5;241m.\u001b[39mget_generation_dict(countryCodes,start_utc,end_utc,imputation_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m import_dict\u001b[38;5;241m=\u001b[39m\u001b[43mentsoe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_import_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountryCodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_utc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_utc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimputation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m export_dict\u001b[38;5;241m=\u001b[39mentsoe\u001b[38;5;241m.\u001b[39mget_export_dict(countryCodes,start_utc,end_utc,imputation_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Daten\\Foschung\\RiskAware\\IntensityLib\\helper\\entsoe_wrapper.py:222\u001b[0m, in \u001b[0;36mget_import_dict\u001b[1;34m(countries, start, end, imputation_type)\u001b[0m\n\u001b[0;32m    219\u001b[0m imp_dict\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imputation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Load generation data for each country and update the set of generation types\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     imp_dict \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_import_data_1h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcountries\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m imputation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     imp_dict \u001b[38;5;241m=\u001b[39m {country_code: get_import_data_1h_imp(country_code, start, end) \u001b[38;5;28;01mfor\u001b[39;00m country_code \u001b[38;5;129;01min\u001b[39;00m countries}\n",
      "File \u001b[1;32mc:\\Daten\\Foschung\\RiskAware\\IntensityLib\\helper\\entsoe_wrapper.py:222\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    219\u001b[0m imp_dict\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imputation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Load generation data for each country and update the set of generation types\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     imp_dict \u001b[38;5;241m=\u001b[39m {country_code: \u001b[43mget_import_data_1h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m country_code \u001b[38;5;129;01min\u001b[39;00m countries}\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m imputation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     imp_dict \u001b[38;5;241m=\u001b[39m {country_code: get_import_data_1h_imp(country_code, start, end) \u001b[38;5;28;01mfor\u001b[39;00m country_code \u001b[38;5;129;01min\u001b[39;00m countries}\n",
      "File \u001b[1;32mc:\\Daten\\Foschung\\RiskAware\\IntensityLib\\helper\\entsoe_wrapper.py:202\u001b[0m, in \u001b[0;36mget_import_data_1h\u001b[1;34m(country, start, end)\u001b[0m\n\u001b[0;32m    200\u001b[0m data\u001b[38;5;241m=\u001b[39mget_import_data(country, start, end)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mprint\u001b[39m(country)\n\u001b[1;32m--> 202\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:9771\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   9768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9769\u001b[0m     convention \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 9771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSeries | DataFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9776\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9781\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9782\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\resample.py:2050\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;124;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2049\u001b[0m tg \u001b[38;5;241m=\u001b[39m TimeGrouper(obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 2050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\resample.py:2272\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   2265\u001b[0m         obj,\n\u001b[0;32m   2266\u001b[0m         timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2269\u001b[0m         gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m   2270\u001b[0m     )\n\u001b[1;32m-> 2272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid with DatetimeIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got an instance of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "#   Load data\n",
    "gen_dict,gen_types=entsoe.get_generation_dict(countryCodes,start_utc,end_utc,imputation_type=\"no\")\n",
    "import_dict=entsoe.get_import_dict(countryCodes,start_utc,end_utc,imputation_type=\"no\") \n",
    "export_dict=entsoe.get_export_dict(countryCodes,start_utc,end_utc,imputation_type=\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Biomass',\n",
       " 'Biomass_Actual Aggregated',\n",
       " 'Biomass_Actual Consumption',\n",
       " 'Fossil Brown coal/Lignite',\n",
       " 'Fossil Brown coal/Lignite_Actual Aggregated',\n",
       " 'Fossil Coal-derived gas',\n",
       " 'Fossil Coal-derived gas_Actual Aggregated',\n",
       " 'Fossil Gas',\n",
       " 'Fossil Gas_Actual Aggregated',\n",
       " 'Fossil Gas_Actual Consumption',\n",
       " 'Fossil Hard coal',\n",
       " 'Fossil Hard coal_Actual Aggregated',\n",
       " 'Fossil Hard coal_Actual Consumption',\n",
       " 'Fossil Oil',\n",
       " 'Fossil Oil shale',\n",
       " 'Fossil Oil shale_Actual Aggregated',\n",
       " 'Fossil Oil_Actual Aggregated',\n",
       " 'Fossil Oil_Actual Consumption',\n",
       " 'Fossil Peat',\n",
       " 'Fossil Peat_Actual Aggregated',\n",
       " 'Fossil Peat_Actual Consumption',\n",
       " 'Geothermal_Actual Aggregated',\n",
       " 'Geothermal_Actual Consumption',\n",
       " 'Hydro Pumped Storage',\n",
       " 'Hydro Pumped Storage_Actual Aggregated',\n",
       " 'Hydro Pumped Storage_Actual Consumption',\n",
       " 'Hydro Run-of-river and poundage',\n",
       " 'Hydro Run-of-river and poundage_Actual Aggregated',\n",
       " 'Hydro Run-of-river and poundage_Actual Consumption',\n",
       " 'Hydro Water Reservoir',\n",
       " 'Hydro Water Reservoir_Actual Aggregated',\n",
       " 'Hydro Water Reservoir_Actual Consumption',\n",
       " 'Marine',\n",
       " 'Marine_Actual Aggregated',\n",
       " 'Nuclear',\n",
       " 'Nuclear_Actual Aggregated',\n",
       " 'Nuclear_Actual Consumption',\n",
       " 'Other',\n",
       " 'Other renewable',\n",
       " 'Other renewable_Actual Aggregated',\n",
       " 'Other renewable_Actual Consumption',\n",
       " 'Other_Actual Aggregated',\n",
       " 'Other_Actual Consumption',\n",
       " 'Solar',\n",
       " 'Solar_Actual Aggregated',\n",
       " 'Solar_Actual Consumption',\n",
       " 'Waste',\n",
       " 'Waste_Actual Aggregated',\n",
       " 'Waste_Actual Consumption',\n",
       " 'Wind Offshore',\n",
       " 'Wind Offshore_Actual Aggregated',\n",
       " 'Wind Offshore_Actual Consumption',\n",
       " 'Wind Onshore',\n",
       " 'Wind Onshore_Actual Aggregated',\n",
       " 'Wind Onshore_Actual Consumption'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_A_stacked(load_dict, export_dict, import_dict, countryCodes, timesteps):\n",
    "    \"\"\"\n",
    "    Build the A matrix for all timesteps using numpy's vectorized operations.\n",
    "\n",
    "    Parameters:\n",
    "    - load_dict: Dictionary containing load data for each country.\n",
    "    - export_dict: Dictionary containing export data for each country.\n",
    "    - import_dict: Dictionary containing import data for each country.\n",
    "    - countryCodes: List of country codes.\n",
    "    - timesteps: Number of timesteps.\n",
    "\n",
    "    Returns:\n",
    "    - A: numpy array of shape (timesteps, n, n)\n",
    "    \"\"\"\n",
    "    n = len(countryCodes)\n",
    "    A = np.zeros((timesteps, n, n))\n",
    "\n",
    "    # Fill the diagonal elements with load data and export data\n",
    "    for i, country_code in enumerate(countryCodes):\n",
    "        load_values = load_dict[country_code].values[:timesteps]\n",
    "        A[:, i, i] = load_values.flatten()\n",
    "        for key in export_dict[country_code].columns:\n",
    "            export_values = export_dict[country_code][key].values[:timesteps]\n",
    "            A[:, i, i] += export_values.flatten()\n",
    "\n",
    "    # Fill the off-diagonal elements with import data\n",
    "    for i, country_code in enumerate(countryCodes):\n",
    "        for j, country_code2 in enumerate(countryCodes):\n",
    "            if country_code != country_code2:\n",
    "                try:\n",
    "                    import_values = import_dict[country_code][country_code2].values[:timesteps]\n",
    "                    A[:, i, j] = -import_values.flatten()\n",
    "                except KeyError:\n",
    "                    A[:, i, j] = 0\n",
    "\n",
    "    return A\n",
    "\n",
    "def get_b_stacked(gen_type, gen_dict, countryCodes, num_timesteps):\n",
    "    b_stack = np.zeros((num_timesteps, len(countryCodes)))\n",
    "    for country_code in countryCodes:\n",
    "            b_stack[:,countryCodes.index(country_code)] = gen_dict[country_code][gen_type][:num_timesteps]\n",
    "    return b_stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def solve_linear_system(A, b):\n",
    "    \"\"\"\n",
    "    Solve the linear system Ax = b for a single timestep.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.full(b.shape, np.nan)  # Return NaNs if the system is singular\n",
    "\n",
    "def solve_linear_systems_parallel(A, b):\n",
    "    \"\"\"\n",
    "    Solve the linear systems Ax = b in parallel for all timesteps.\n",
    "\n",
    "    Parameters:\n",
    "    - A: numpy array of shape (timesteps, n, n)\n",
    "    - b: numpy array of shape (timesteps, n)\n",
    "\n",
    "    Returns:\n",
    "    - x: numpy array of shape (timesteps, n) containing the solutions\n",
    "    \"\"\"\n",
    "    timesteps = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    # Initialize the result array\n",
    "    x = np.zeros((timesteps, n))\n",
    "    \n",
    "    # Use ThreadPoolExecutor to parallelize the computation\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(solve_linear_system, A, b))\n",
    "    \n",
    "    # Collect the results\n",
    "    for i, result in enumerate(results):\n",
    "        x[i] = result\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_type='Wind Onshore'\n",
    "num_timesteps=1\n",
    "\n",
    "A_stack = get_A_stacked(gen_dict, export_dict, import_dict, countryCodes, num_timesteps) \n",
    "x=np.zeros((len(gen_types),num_timesteps,len(countryCodes)))\n",
    "for i,gen_type in enumerate(gen_types):\n",
    "    b_stack = get_b_stacked(gen_type, gen_dict, countryCodes, num_timesteps)\n",
    "    x[i,:,:] = solve_linear_systems_parallel(A_stack, b_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty set for generation types\n",
    "gen_types = set()\n",
    "storage_dict = {}\n",
    "# Load generation data for each country and update the set of generation types\n",
    "for country in countryCodes:\n",
    "    gen_df= utils.load_generation_data(country)\n",
    "    gen_df= gen_df.resample('h').mean()\n",
    "    if \"Hydro Pumped Storage - Actual Consumption [MW]\" in gen_df.columns:\n",
    "        storage_dict[country] = gen_df[\"Hydro Pumped Storage - Actual Consumption [MW]\"].fillna(0)\n",
    "        gen_df.drop(columns=[\"Hydro Pumped Storage - Actual Consumption [MW]\"], inplace=True)\n",
    "    else:\n",
    "        storage_dict[country] = pd.Series(np.zeros(len(gen_df)), index=gen_df.index)\n",
    "    gen_dict[country] = gen_df\n",
    "    \n",
    "for gen_data in gen_dict.values():\n",
    "    gen_types.update(gen_data.columns)\n",
    "# Add all columns that are missing in each country's dataframe\n",
    "for country_code in countryCodes:\n",
    "    for gen_type in gen_types:\n",
    "        if gen_type not in gen_dict[country_code].columns:\n",
    "            gen_dict[country_code][gen_type] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "netimp_dict={}\n",
    "for country_code in countryCodes:\n",
    "    netimp_dict[country_code]=import_dict[country_code]-export_dict[country_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrycodes_new = [country for country in countryCodes if gen_dict[country].iloc[0].isna().sum() < 1 and netimp_dict[country].iloc[0].isna().sum() < 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the generation based on imports from other countries\n",
    "def scale_generation(gen_dict, import_dict, countries):\n",
    "    scaled_gen_dict ={}\n",
    "    # Calculate the total import from countries not included in the topology\n",
    "    for country_code in countries:\n",
    "            # total import from countries not included in the topology\n",
    "            sum=0\n",
    "            for country in import_dict[country_code].keys():\n",
    "                  if country not in countries:\n",
    "                        sum+=import_dict[country_code][country].iloc[0]          \n",
    "            scaled_gen_dict[country_code] = gen_dict[country_code].iloc[0] * (1 + sum / gen_dict[country_code].iloc[0].sum())\n",
    "    return scaled_gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_gen_dict=scale_generation(gen_dict, import_dict, countrycodes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the right hand side\n",
    "# Numpy Vector with generation plus storage discharge\n",
    "def get_b(gen_type, countryCodes):\n",
    "    b = np.zeros(len(countryCodes))\n",
    "    \n",
    "    for i, country_code in enumerate(countryCodes):\n",
    "        b[i] = scaled_gen_dict[country_code][gen_type]\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A(countrycodes_new):\n",
    "    A=np.zeros((len(countrycodes_new),len(countrycodes_new)))\n",
    "    for i,country_code in enumerate(countrycodes_new):\n",
    "        for s,country_code2 in enumerate(countrycodes_new):\n",
    "            if i==s:\n",
    "                A[i,s]=(gen_dict[country_code].sum(axis=1).iloc[0])\n",
    "                for key in netimp_dict[country_code].columns:\n",
    "                        if key in countrycodes_new:\n",
    "                            A[i,s] += netimp_dict[country_code][key].iloc[0]\n",
    "                        else:\n",
    "                            A[i,s] +=import_dict[country_code][key].iloc[0]\n",
    "                            #A[i,s] -=export_dict[country_code][key].iloc[0] \n",
    "            else:\n",
    "                if i<s:\n",
    "                    try:\n",
    "                        A[i,s]=-netimp_dict[country_code][country_code2].iloc[0]\n",
    "                    except:\n",
    "                        A[i,s]=0\n",
    "                else:\n",
    "                    try:\n",
    "                        A[i,s]=-netimp_dict[country_code][country_code2].iloc[0]\n",
    "                    except:\n",
    "                        A[i,s]=0\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q=dict()\n",
    "A=get_A(countrycodes_new)\n",
    "\n",
    "# Solve the linear equiation system for one technology\n",
    "sum=0\n",
    "for gen_type in gen_types:\n",
    "    b=get_b(gen_type,countrycodes_new)\n",
    "    sum+=b\n",
    "    q[gen_type]=np.linalg.solve(A,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=0\n",
    "for gen_type in gen_types:\n",
    "    sum+=q[gen_type]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
